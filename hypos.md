To investigate the research questions above, an experiment similar to Conaway & Kurtz (2016) will be conducted. The basic proceeding is: participants will receive instructions for the task at hand, undergo a training phase of an incomplete XOR task with 12 blocks of 8 trials each (96 trials in total), receive yet another instructional prompt and then complete a transfer phase with 49 trials, of which 9 are the "missing" ones from training phase to constitute a full-XOR set of stimuli. 

There will be a total of 4 groups:
1. A control group A that will receive to experimental treatment; that is, no rule-related language in the instructions as well as the full set of training stimuli from the get-go.
2. A group B that will encounter rule-related language, but no 'simple rule first' (see next point).
3. A group C that will encounter no rule-related language, but a reduced set of stimuli before the full set, such that they only have to learn a very simple rule (a type I solution in SHJ-terms) before encountering the full set (resulting in an incomplete XOR solution)
4. A group D that will encounter rule-related language in the instructions as well as a simple rule first.

With that, we can establish these hypotheses:

**H1:** There will be a main effect of rule related language (${BF}_{rrl} > )

**H1.1:** There will be a main effect of rule related language on the overall accuracy during training ($\mu_{Acc, B} > \mu_{Acc, A}$)  
**H1.2:** There will be a main effect of rule related language on the number of extrapolated responses on the nine critcal items during the generalization phase ($k_B > k_A$)

**H2.1:** There will be a main effect of the simple rule first condition on the overall accuracy during training ($\mu_{Acc, C} > \mu_{Acc, A}$)  
**H2.2:** There will be a main effect of the simple rule first condition on the number of extrapolated responses on the nine critcal items during the generalization phase ($k_C > k_A$)

The relation between the effect of rule ordering and the effect of rule related language is unclear as of yet; whether the one is larger than the other, if they are additive or whether they're interacting in any way at all. Therefore the third set of hypotheses is undirected:

**H3.1:** The combination of rule related language and rule ordering will result in a difference of accuracy to groups receiving only one or neither of those treatments ($\mu_{Acc, D} \neq \mu_{Acc, A}, \mu_{Acc, B}, \mu_{Acc, C}$)  
**H3.1:** The combination of rule related language and rule ordering will result in a difference to the number of extrapolated responses during the generalization phase to groups receiving only one or neither of those treatments ($k_D \neq k_A, k_B, k_C$)

Since the experimental procedure occurs in sequential blocks of randomized trials, we can also hypothesize about the speed in which high accuracies will be achieved between the different experimental conditions. It seems likely that in later stages (or blocks) of the training phase, participants in any condition will have "figured it out", whereas in earlier stages, Groups B-D should have a learning advantage of some sort over Group A. Thus:

**H4:** There will be an interaction regarding the accuracy between experimental conditions at different stages during the training phase ($\mu_{A_{1-12}} \neq \mu_{B_{1-12}} \neq \mu_{C_{1-12}} \neq \mu_{D_{1-12}}$)


<!--- An additive effect seems most likely as both experimental modulations aim to aid the subjects in categorization / rule learning in a different way. Therefore we propose the following hypotheses regarding the fit of our models:

H3: There will be a difference in the effects of rule related language and rule ordering (Mod_AB != Mod_AC)
H4: Both effects in question will yield -->



# Research questions

RQ1: Does rule-related language facilitate category extrapolation of the novel stimuli during the transfer phase?
RQ2: Does the learning of a simple rule structure followed by a more complex one facilitate extrapolation?

maybe Evan Betteryet (2022):

RQ1.1: Does the mentioning of rules lead to better learning performance / higher categorization accuracy?
RQ1.2: Does it lead _faster_ reaching high catgeorization accuracies?
RQ1.3: Does it lead to more extrapolations of unlearned stimulus categories?

RQ2.1: Does learning a simple categorisation rule before encountering a more complex one lead to better learning performance?
RQ2.2: 

# Hypotheses - New and improved

- **H1:** Main effect of 'rule related language' (rrl)
- **H1.1:** _(directed)_ higher odds of correct categorization during training
- **H1.2:** _(directed)_ higher odds of extrapolating categories during transfer

- **H2:** Main effect of 'simple rule first' (rrl)
- **H2.1:** _(directed)_ higher odds of correct categorization during training
- **H2.2:** _(directed)_ higher odds of extrapolating categories during transfer

<!--
- **H3:** Interaction of rrl and srf
- **H3.1:** _(undirected)_ change in odds of extrapolation during transfer
-->

**H4:** Interaction of main effects (h1 & 2) with training blocks




# Real Deal

## Research questions

1.1 Does learning a simple rule before encountering a more complex one facilitate the extrapolation of novel stimuli?
1.2 Does rule-related language facilitate the extrapolation of novel stimuli?

2. Does the learning process improve by...
2.1 ...using rule related language?
2.2 ...first learning a simple followed by a more complex one?

2. Does the increase in extrapolations also lead to a better learning performance...
2.1 
2.2 when using rule related language?

3. Are response times in a 'simple rule first' condition affected by a rule-switch - that is, by novel items?

4. Apart from categorical decisions, is there a relation between probability judgements regarding an items category and the respective items specificity? (might need some work, wording-wise; question is: "are probability judgements higher for items belonging to either one category, the more extreme the items dimensional characteristic? That is: "The 'blacker' or 'whiter', smaller or bigger the item, the higher the probability judgement?")



### Hypotheses

1.1 (directed) Higher number of extrapolations for the items of the untrained/incomplete category in the 'simple rule first' condition
1.2 (directed) Higher number of extrapolations for the items of the untrained/incomplete category in the 'simple rule first' condition
1.3 (undirected) Interaction of the 'simple rule first' and the 'rule related language' condition on the number of extrapolations of the untrained/incomplete category

2.1 (undirected) Interaction of learning accuracy between training block (1-10) and rule related language (vs. no mentioning of rules) in the simple rule first condition
2.2 (undirected) same as 2.1 but in the mixed rules condition
2.3 (directed) Learning accuracy will be higher when exposed to rule related language (vs. no mentioning of rules) in the mixed rules condition...
2.4 ...as well as in the simple rule first condition

3.1 (directed) Response times for established items will be lower than for novel items in training
3.2 (directed) Response times for trained categories will be lower than for the untrained category in transfer

4.1 (directed) Probability judgements are higher for items with more extreme dimensional characteristics



Varianz (in transfer):
trained_item > trained_category ~= untrained_category > unequivocal_item ("midlanes")   ...?


