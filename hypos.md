To investigate the research questions above, an experiment similar to Conaway & Kurtz (2016) will be conducted. The basic proceeding is: participants will receive instructions for the task at hand, undergo a training phase of an incomplete XOR task with 12 blocks of 8 trials each (96 trials in total), receive yet another instructional prompt and then complete a generalization phase with 49 trials, of which 9 are the "missing" ones from training phase to constitute a full-XOR set of stimuli. 

There will be a total of 4 groups:
1. A control group A that will receive to experimental treatment; that is, no rule-related language in the instructions as well as the full set of training stimuli from the get-go.
2. A group B that will receive rule-related language, but no 'simple rule first' (see next point).
3. A group C that will receive no rule-related language, but will encounter a reduced set of stimuli before the full set, such that they only have to learn a very simple rule (a type I solution in SHJ-terms) before encountering the full set (resulting in an incomplete XOR solution)
4. A group D that will receive rule-related language in the instructions as well as a simple rule first.

With that, we can establish these hypotheses:

**H1.1:** There will be a main effect of rule related language on the overall accuracy during training ($\mu_{Acc, B} > \mu_{Acc, A}$)  
**H1.2:** There will be a main effect of rule related language on the number of extrapolated responses on the nine critcal items during the generalization phase ($k_B > k_A$)

**H2.1:** There will be a main effect of the simple rule first condition on the overall accuracy during training ($\mu_{Acc, C} > \mu_{Acc, A}$)  
**H2.2:** There will be a main effect of the simple rule first condition on the number of extrapolated responses on the nine critcal items during the generalization phase ($k_C > k_A$)

The relation between the effect of rule ordering and the effect of rule related language is unclear as of yet; whether the one is larger than the other, if they are additive or whether they're interacting in any way at all. Therefore the third set of hypotheses is undirected:

**H3.1:** The combination of rule related language and rule ordering will result in a difference of accuracy to groups receiving only one or neither of those treatments ($\mu_{Acc, D} \neq \mu_{Acc, A}, \mu_{Acc, B}, \mu_{Acc, C}$)  
**H3.1:** The combination of rule related language and rule ordering will result in a difference to the number of extrapolated responses during the generalization phase to groups receiving only one or neither of those treatments ($k_D \neq k_A, k_B, k_C$)

Since the experimental procedure occurs in sequential blocks of randomized trials, we can also hypothesize about the speed in which high accuracies will be achieved between the different experimental conditions. It seems likely that in later stages (or blocks) of the training phase, participants in any condition will have "figured it out", whereas in earlier stages, Groups B-D should have a learning advantage of some sort over Group A. Thus:

**H4:** There will be an interaction regarding the accuracy between experimental conditions at different stages during the training phase ($\mu_{A_{1-12}} \neq \mu_{B_{1-12}} \neq \mu_{C_{1-12}} \neq \mu_{D_{1-12}}$)


<!--- An additive effect seems most likely as both experimental modulations aim to aid the subjects in categorization / rule learning in a different way. Therefore we propose the following hypotheses regarding the fit of our models:

H3: There will be a difference in the effects of rule related language and rule ordering (Mod_AB != Mod_AC)
H4: Both effects in question will yield -->
